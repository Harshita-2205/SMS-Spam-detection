{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\harshita\\anaconda3\\lib\\site-packages (1.6.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from bleach->kaggle) (22.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'imkdir' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!imkdir -p ~/.kaggle/\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset\n",
      "License(s): unknown\n",
      "sms-spam-collection-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset extracted :)\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "dataset = 'sms-spam-collection-dataset.zip'\n",
    "\n",
    "with ZipFile(dataset,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print(' dataset extracted :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('spam.csv',encoding='ISO-8859-1')\n",
    "\n",
    "#NO. of rows and cols\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "df.info()\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\n",
    "df.rename(columns={'v1':'label','v2':'message'},inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "df['label'].replace({'ham':0,'spam':1},inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HARSHITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HARSHITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = [ps.stem(word) for word in filtered_text]\n",
    "    return ' '.join(stemmed_text)\n",
    "df['message'] = df['message'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5169,) (4135,) (1034,)\n",
      "(4135, 6230) (1034, 6230)\n"
     ]
    }
   ],
   "source": [
    "#splitting the data\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(X.shape,X_train.shape,X_test.shape)\n",
    "print(X_train_tfidf.shape,X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy: 0.9661508704061895 Precision: 1.0 Recall: 0.7586206896551724 F1 Score: 0.8627450980392157\n",
      "Training Confusion Matrix:\n",
      "[[3627    0]\n",
      " [  96  412]]\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(chi2, k=6230)\n",
    "X_train_selected = selector.fit_transform(X_train_tfidf, y_train)\n",
    "X_test_selected = selector.transform(X_test_tfidf)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nb = nb.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Naive Bayes classifier\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "# Set pos_label to 1 to match your target labels\n",
    "precision_nb = precision_score(y_test, y_pred_nb, pos_label=1)  \n",
    "recall_nb = recall_score(y_test, y_pred_nb, pos_label=1)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, pos_label=1)\n",
    "train_confusion = confusion_matrix(y_train, nb.predict(X_train_tfidf)) # Calculate confusion matrix for training data\n",
    "test_confusion = confusion_matrix(y_test, y_pred_nb) # Calculate confusion matrix for testing data\n",
    "\n",
    "print(\"Naive Bayes - Accuracy:\", accuracy_nb, \"Precision:\", precision_nb, \"Recall:\", recall_nb, \"F1 Score:\", f1_nb)\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.9671179883945842 Precision: 0.9826086956521739 Recall: 0.7793103448275862 F1 Score: 0.8692307692307693\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression classifier\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_lr = lr.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Logistic Regression classifier\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "# Assuming 1 represents 'spam' in your dataset\n",
    "precision_lr = precision_score(y_test, y_pred_lr, pos_label=1)  \n",
    "recall_lr = recall_score(y_test, y_pred_lr, pos_label=1)  \n",
    "f1_lr = f1_score(y_test, y_pred_lr, pos_label=1)  \n",
    "print(\"Logistic Regression - Accuracy:\", accuracy_lr, \"Precision:\", precision_lr, \"Recall:\", recall_lr, \"F1 Score:\", f1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine - Accuracy: 0.9806576402321083 Precision: 1.0 Recall: 0.8620689655172413 F1 Score: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# Train Support Vector Machine classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Support Vector Machine classifier\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# Set pos_label to 1 to be consistent with previous evaluations \n",
    "precision_svm = precision_score(y_test, y_pred_svm, pos_label=1)  \n",
    "recall_svm = recall_score(y_test, y_pred_svm, pos_label=1)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, pos_label=1)\n",
    "print(\"Support Vector Machine - Accuracy:\", accuracy_svm, \"Precision:\", precision_svm, \"Recall:\", recall_svm, \"F1 Score:\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.976784</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.862745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.963482</td>\n",
       "      <td>0.967118</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.869231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.997582</td>\n",
       "      <td>0.980658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Accuracy  Test Accuracy  Test Precision  \\\n",
       "0             Naive Bayes        0.976784       0.966151        1.000000   \n",
       "1     Logistic Regression        0.963482       0.967118        0.982609   \n",
       "2  Support Vector Machine        0.997582       0.980658        1.000000   \n",
       "\n",
       "   Test Recall  Test F1 Score  \n",
       "0     0.758621       0.862745  \n",
       "1     0.779310       0.869231  \n",
       "2     0.862069       0.925926  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\" : MultinomialNB(),\n",
    "    \"Logistic Regression\" : LogisticRegression(),\n",
    "    \"Support Vector Machine\" : SVC()\n",
    "}\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train_tfidf))\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    test_recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    train_confusion = confusion_matrix(y_train, model.predict(X_train_tfidf))\n",
    "    test_confusion = confusion_matrix(y_test, y_pred)\n",
    "  \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Test Precision\": test_precision,\n",
    "        \"Test Recall\": test_recall,\n",
    "        \"Test F1 Score\": test_f1\n",
    "    })\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assume we have a trained model and a vectorizer\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('spam_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Save the vectorizer to a file\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit==1.29.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.29.0)\n",
      "Requirement already satisfied: pandas==2.1.4 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: pillow==10.2.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: nltk==3.8.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (4.11.3)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (4.21.12)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (5.3.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (8.4.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (0.8.1b0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (4.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (13.3.5)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (2.1.6)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (22.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (16.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (1.6.2)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from streamlit==1.29.0->-r requirements.txt (line 1)) (6.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 2)) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from nltk==3.8.1->-r requirements.txt (line 5)) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from nltk==3.8.1->-r requirements.txt (line 5)) (4.66.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (4.17.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: toolz in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit==1.29.0->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.29.0->-r requirements.txt (line 1)) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit==1.29.0->-r requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit==1.29.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.29.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.29.0->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.29.0->-r requirements.txt (line 1)) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.29.0->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.29.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.29.0->-r requirements.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from tzlocal<6,>=1.1->streamlit==1.29.0->-r requirements.txt (line 1)) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from validators<1,>=0.2->streamlit==1.29.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.29.0->-r requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.29.0->-r requirements.txt (line 1)) (22.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\harshita\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit==1.29.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
